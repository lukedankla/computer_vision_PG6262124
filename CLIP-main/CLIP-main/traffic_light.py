import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.ops import sigmoid_focal_loss

class BEVTransformer(nn.Module):
    def __init__(self, input_channels=3):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.bev_projection = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Upsample(scale_factor=2),
        )

    def forward(self, x):
        x = self.encoder(x)
        return self.bev_projection(x)

class TelemetryEncoder(nn.Module):
    def _init_(self, telemetry_dim=4):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(telemetry_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 64),
        )
        
    def forward(self, x):
        return self.net(x)

class MMLFusion(nn.Module):
    def _init_(self, use_lidar=True):
        super().__init__()
        self.use_lidar = use_lidar
        if use_lidar:
            self.lidar_net = nn.Sequential(
                nn.Conv2d(1, 32, 3, padding=1),
                nn.BatchNorm2d(32),
                nn.ReLU(),
            )
        self.telemetry_encoder = TelemetryEncoder()
        self.fusion = nn.Sequential(
            nn.Conv2d(256 + (32 if use_lidar else 0) + 64, 256, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
        )

    def forward(self, bev_feats, lidar=None, telemetry=None):
        if self.use_lidar and lidar is not None:
            lidar_feats = self.lidar_net(lidar)
            bev_feats = torch.cat([bev_feats, lidar_feats], dim=1)
        
        if telemetry is not None:
            telemetry_feats = self.telemetry_encoder(telemetry)
            telemetry_feats = telemetry_feats.view(-1, 64, 1, 1).expand(-1, -1, *bev_feats.shape[2:])
            bev_feats = torch.cat([bev_feats, telemetry_feats], dim=1)
            
        return self.fusion(bev_feats)

class YOLOv8Head(nn.Module):
    def __init__(self, num_classes=3, num_anchors=3):
        super().__init__()
        self.num_classes = num_classes
        self.num_anchors = num_anchors
        self.detection = nn.Sequential(
            nn.Conv2d(256, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.SiLU(),
            nn.Conv2d(512, (5 + num_classes) * num_anchors, 1),
        )
        
    def forward(self, x):
        return self.detection(x)

class BEVYOLOMML(nn.Module):
    def __init__(self, num_classes=3, use_lidar=True):
        super().__init__()
        self.bev_transform = BEVTransformer()
        self.mml_fusion = MMLFusion(use_lidar=use_lidar)
        self.yolo_head = YOLOv8Head(num_classes)
        
    def forward(self, img, lidar=None, telemetry=None):
        bev_feats = self.bev_transform(img)
        fused_feats = self.mml_fusion(bev_feats, lidar, telemetry)
        return self.yolo_head(fused_feats)

class TrafficLightLoss(nn.Module):
    def __init__(self, num_classes=3):
        super().__init__()
        self.num_classes = num_classes
        
    def forward(self, preds, targets):
        # preds: (batch, anchors*(5+num_classes), H, W)
        # targets: list of (box, class) tensors
        
        # Reshape predictions
        B, _, H, W = preds.shape
        preds = preds.view(B, self.num_anchors, 5 + self.num_classes, H, W)
        preds = preds.permute(0, 1, 3, 4, 2)
        
        # Split predictions
        pred_boxes = preds[..., :4]  # xywh
        pred_obj = preds[..., 4:5]   # objectness
        pred_cls = preds[..., 5:]    # class probabilities
        
        # Calculate losses
        box_loss = self._calculate_box_loss(pred_boxes, targets['boxes'])
        obj_loss = F.binary_cross_entropy_with_logits(pred_obj, targets['obj'])
        cls_loss = F.cross_entropy(pred_cls, targets['cls'])
        
        return box_loss + obj_loss + cls_loss
    
    def _calculate_box_loss(self, pred_boxes, target_boxes):
        # CIoU loss implementation
        # ... (detailed implementation omitted for brevity)
        pass

# Example usage
if __name__ == "_main_":
    # Initialize model
    model = BEVYOLOMML(num_classes=3, use_lidar=True)
    
    # Example inputs
    img = torch.randn(2, 3, 256, 256)  # batch of RGB images
    lidar = torch.randn(2, 1, 256, 256) # batch of LiDAR depth maps
    telemetry = torch.randn(2, 4)       # batch of telemetry vectors
    
    # Forward pass
    outputs = model(img, lidar, telemetry)
    print(f"Output shape: {outputs.shape}")  # Should be (2, 24, H, W)
    
    # Loss calculation example
    criterion = TrafficLightLoss()
    targets = {
        'boxes': torch.randn(2, 4),  # example boxes
        'obj': torch.rand(2, 1),    # objectness
        'cls': torch.randint(0, 3, (2,))  # classes
    }
    loss = criterion(outputs, targets)
    print(f"Total loss:Â {loss.item()}")